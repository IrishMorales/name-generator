{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technical Implementation - Part 1\n",
    "### For a list of names dataset, how will the vectorized version look like? The hyperparameter maxlen should be set to a fixed value. Why is this the case? Show your solution in a jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating mappings for characters & indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read names to use as training data\n",
    "filename = \"names.txt\"\n",
    "f = open(filename, 'r')\n",
    "\n",
    "raw_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size (Total Characters): 53\n"
     ]
    }
   ],
   "source": [
    "# Get unique characters from the training data as our vocabulary\n",
    "characters = sorted(list(set(raw_text)))\n",
    "print(f\"Vocabulary Size (Total Characters): {len(characters)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the index of a given character\n",
    "character_indices = dict((c, i) for i,c in enumerate(characters))\n",
    "\n",
    "# Returns the character given an index\n",
    "indices_characters = dict((i, c) for i, c in enumerate(characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " 'A': 1,\n",
       " 'B': 2,\n",
       " 'C': 3,\n",
       " 'D': 4,\n",
       " 'E': 5,\n",
       " 'F': 6,\n",
       " 'G': 7,\n",
       " 'H': 8,\n",
       " 'I': 9,\n",
       " 'J': 10,\n",
       " 'K': 11,\n",
       " 'L': 12,\n",
       " 'M': 13,\n",
       " 'N': 14,\n",
       " 'O': 15,\n",
       " 'P': 16,\n",
       " 'Q': 17,\n",
       " 'R': 18,\n",
       " 'S': 19,\n",
       " 'T': 20,\n",
       " 'U': 21,\n",
       " 'V': 22,\n",
       " 'W': 23,\n",
       " 'X': 24,\n",
       " 'Y': 25,\n",
       " 'Z': 26,\n",
       " 'a': 27,\n",
       " 'b': 28,\n",
       " 'c': 29,\n",
       " 'd': 30,\n",
       " 'e': 31,\n",
       " 'f': 32,\n",
       " 'g': 33,\n",
       " 'h': 34,\n",
       " 'i': 35,\n",
       " 'j': 36,\n",
       " 'k': 37,\n",
       " 'l': 38,\n",
       " 'm': 39,\n",
       " 'n': 40,\n",
       " 'o': 41,\n",
       " 'p': 42,\n",
       " 'q': 43,\n",
       " 'r': 44,\n",
       " 's': 45,\n",
       " 't': 46,\n",
       " 'u': 47,\n",
       " 'v': 48,\n",
       " 'w': 49,\n",
       " 'x': 50,\n",
       " 'y': 51,\n",
       " 'z': 52}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "character_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to a Set of Symbols of Fixed Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 10\n",
    "step = 2\n",
    "\n",
    "data_points = []\n",
    "next_characters = []\n",
    "\n",
    "for i in range(0, len(raw_text) - maxlen, step):\n",
    "    data_points.append(raw_text[i: i+maxlen])\n",
    "    next_characters.append(raw_text[i + maxlen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Michael\\nCh', 'chael\\nChri', 'ael\\nChrist']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the first few elements of data_points for inspection\n",
    "data_points[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['r', 's', 'o']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the first few elements of next_characters for inspection\n",
    "next_characters[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points: 66774\n"
     ]
    }
   ],
   "source": [
    "# Print the number of observations/data points generated from the dataset\n",
    "print(f\"Number of data points: {len(data_points)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data_points into x and characters into y\n",
    "import numpy as np\n",
    "\n",
    "x = np.zeros((len(data_points), maxlen, len(characters)), dtype=int)\n",
    "y = np.zeros((len(data_points), len(characters)), dtype=int) \n",
    "# dtype = int is used above for the purposes of demonstrating the vectors, \n",
    "# however in actual implementation it should be set to dtype = np.float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create one hot encoding of data_points and characters\n",
    "for i, data_point in enumerate(data_points):\n",
    "    for t, character, in enumerate(data_point):\n",
    "        x[i, t, character_indices[character]] = 1\n",
    "    y[i, character_indices[next_characters[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For a list of names dataset, how will the vectorized version look like?\n",
    "From the list of names dataset, we generate an x vector (observations/data points) and a y vector (predicted next characters). We look at the y vector first:\n",
    "\n",
    "The y vector (predicted next characters) can be thought of as an array of arrays. Each array inside is the size of the vocabulary, and the array contains a '1' at the index corresponding to the character and '0' everywhere else. Thus, the shape of y will be `the number of data points` x `the vocabulary size`.\n",
    "\n",
    "For example, our vocabulary size (number of unique characters from the dataset) is 53. y is an array of arrays, wherein each array inside has 53 elements. When we printed `next_characters` earlier, the first predicted next character is 'r'. Looking at `character_indices`, 'r' is at index 44. Thus, the first array in y has '1' at index 44 and '0' everywhere else. We can verify this by inspecting y below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:3] # the first few arrays in y, showing y is an array of arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0] # the first array in y, which corresponds to 'r' (the first element in next_characters)\n",
    "# 'r' is represented by '1' at index 44 and '0' everywhere else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0][44] # show that '1' is at index 44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'r'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_characters[44] # show that index 44 corresponds to 'r'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66774, 53)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape\n",
    "# The shape of y will be: the number of data points,\n",
    "# the number of characters in our vocabulary (vocabulary size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we look at the x vector. Whereas y can be thought of as a 2D array, x is a 3D array. That is, while y itself is an array of arrays, each element in x is an array of arrays.\n",
    "\n",
    "For example, when we printed `data_points` earlier, the first element is 'Michael\\nCh' (an array of arrays). Each character in 'Michael\\nCh' is represented as an array in the same way y represented one character. Looking at `character_indices`, 'M' is one array with '1' at index 13, 'i' is one array with '1' at index 35, and so on.\n",
    "\n",
    "Looking at `character_indices`, 'r' is at index 44. Thus, the first array in y has '1' at index 44 and '0' everywhere else. We can verify this by inspecting x below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:2] # the first few elements of x, showing x is a 3D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0] # the first element of x, which is an array of arrays corresponding to 'Michael\\nCh' (the first element in data_points)\n",
    "# the first array is for 'M', represented by '1' at index 13 and '0' everywhere else\n",
    "# the second array is for 'i', represented by '1' at index 35 and '0' everywhere else, and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66774, 10, 53)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape\n",
    "# The shape of x will be: the number of data points, \n",
    "# the number of characters per data point (maxlen),\n",
    "# the number of characters in our vocabulary (vocabulary size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The hyperparameter maxlen should be set to a fixed value. Why is this the case?\n",
    "The names themselves have varying lengths (ex. Michael has length 7, Christian has length 9), however, MLP requires that inputs must all have the same size. To resolve this, the textual dataset is split using `maxlen` into data points that all have the same dimensionality (length).\n",
    "\n",
    "For example, `maxlen` was set to 10 above. Thus, whereas the original text has names of varying lengths, the inputs become 'Michael\\nCh', 'chael\\nChri', 'ael\\nChrist', and so on, each of length 10. The split inputs can then be passed through the MLP model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technical Implementation - Part 2\n",
    "### Convert the notebook Intuition for Text Generation notebook to a word token level (as opposed to character level token) and see what gets generated.\n",
    "This notebook shows an end to end process for the objective of generating text on a word token level. It first reads a text file as defined in `story.txt` and performs the following:\n",
    "\n",
    "* Text Cleanup by lowercasing everything\n",
    "* Text Cleanup by removing unwanted symbols\n",
    "* Creating a mapping for character indices and indices to characters\n",
    "* Defining x and y vectors for classification\n",
    "* Pass it to a multi-layer perceptron\n",
    "* Generate some text\n",
    "\n",
    "## Required Libraries\n",
    "\n",
    "* `nltk`\n",
    "* `scikit-learn`\n",
    "* `torch`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Irish\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Irish\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Irish\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read a Text File and Get Raw Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"story.txt\"\n",
    "f = open(filename, 'r')\n",
    "\n",
    "raw_text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine First 1000 Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Once upon a time, there was a boy named Mike\\nHe was raised in the hood, life was never quite\\nGrowing up, he faced many struggles and strife\\nBut through it all, he had one love in his life\\n\\nRap music was his escape from reality\\nThe beats and lyrics helped him to see\\nA world beyond his troubled neighborhood\\nHe knew that with hard work, he could change his mood\\n\\nHe started writing rhymes and practicing his flow\\nIn the mirror, he would rap and watch himself grow\\nHe knew that if he could just make it to the top\\nHe could change his life, and make a better stop\\n\\nOne day, he had the chance to perform on stage\\nIn front of a crowd, he killed it, he killed it with rage\\nHe had finally made it, he had achieved his dream\\nAnd now he is a successful rapper, or so it seems\\n\\nHe never forgot where he came from, and he never will\\nHe always remember the struggles that he had to fulfill\\nHe is now a role model to kids in the hood\\nShowing them that with hard work, they too could\\n\\nRise above their circumstance'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text[0:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup Text\n",
    "* Lowercase all characters\n",
    "* Remove special symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'once upon a time, there was a boy named mike\\nhe was raised in the hood, life was never quite\\ngrowing up, he faced many struggles and strife\\nbut through it all, he had one love in his life\\n\\nrap music was his escape from reality\\nthe beats and lyrics helped him to see\\na world beyond his troubled neighborhood\\nhe knew that with hard work, he could change his mood\\n\\nhe started writing rhymes and practicing his flow\\nin the mirror, he would rap and watch himself grow\\nhe knew that if he could just make it to the top\\nhe could change his life, and make a better stop\\n\\none day, he had the chance to perform on stage\\nin front of a crowd, he killed it, he killed it with rage\\nhe had finally made it, he had achieved his dream\\nand now he is a successful rapper, or so it seems\\n\\nhe never forgot where he came from, and he never will\\nhe always remember the struggles that he had to fulfill\\nhe is now a role model to kids in the hood\\nshowing them that with hard work, they too could\\n\\nrise above their circumstances and chase their dreams\\nand make a better life, or so it seems\\n\\nthe end'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_text = raw_text.lower()\n",
    "processed_text = re.sub(r'[^\\x00-\\x7f]', r'', processed_text)\n",
    "\n",
    "processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokens = word_tokenize(processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_tokens = [token for token in word_tokens if token.lower() not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vocabulary = list(set(sorted(filtered_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['life',\n",
       " 'remember',\n",
       " 'helped',\n",
       " 'forgot',\n",
       " 'escape',\n",
       " 'quite',\n",
       " 'chance',\n",
       " 'came',\n",
       " 'grow',\n",
       " 'watch',\n",
       " 'killed',\n",
       " 'knew',\n",
       " 'dream',\n",
       " 'raised',\n",
       " 'showing',\n",
       " 'mirror',\n",
       " 'stop',\n",
       " 'made',\n",
       " 'flow',\n",
       " 'one',\n",
       " 'time',\n",
       " 'many',\n",
       " 'seems',\n",
       " 'always',\n",
       " 'end',\n",
       " 'better',\n",
       " 'practicing',\n",
       " 'reality',\n",
       " 'role',\n",
       " ',',\n",
       " 'perform',\n",
       " 'neighborhood',\n",
       " 'front',\n",
       " 'fulfill',\n",
       " 'achieved',\n",
       " 'named',\n",
       " 'beat',\n",
       " 'kid',\n",
       " 'world',\n",
       " 'strife',\n",
       " 'hard',\n",
       " 'rapper',\n",
       " 'successful',\n",
       " 'would',\n",
       " 'boy',\n",
       " 'mood',\n",
       " 'finally',\n",
       " 'hood',\n",
       " 'rap',\n",
       " 'rage',\n",
       " 'writing',\n",
       " 'top',\n",
       " 'love',\n",
       " 'upon',\n",
       " 'circumstance',\n",
       " 'model',\n",
       " 'chase',\n",
       " 'crowd',\n",
       " 'rhyme',\n",
       " 'faced',\n",
       " 'stage',\n",
       " 'change',\n",
       " 'struggle',\n",
       " 'day',\n",
       " 'lyric',\n",
       " 'mike',\n",
       " 'troubled',\n",
       " 'growing',\n",
       " 'started',\n",
       " 'never',\n",
       " 'make',\n",
       " 'see',\n",
       " 'could',\n",
       " 'music',\n",
       " 'dream',\n",
       " 'work',\n",
       " 'beyond',\n",
       " 'rise']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_tokens = [lemmatizer.lemmatize(token) for token in word_vocabulary]\n",
    "\n",
    "lemmatized_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Index Mappings\n",
    "\n",
    "* `word_indices`: Return the index of a given word. Example: `word_indices['a']`\n",
    "* `indices_word`: Returns the word given an index. Example: `indices_word[0]`\n",
    "\n",
    "In this case, `word` serves as your **vocabulary**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Words: 77\n"
     ]
    }
   ],
   "source": [
    "words = sorted(list(set(lemmatized_tokens)))\n",
    "print(\"Total Words: {}\".format(len(words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_indices = dict((w, i) for i,w in enumerate(words))\n",
    "indices_words = dict((i, w) for i,w in enumerate(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to a Set of Symbols of Fixed Length\n",
    "\n",
    "* `maxlen`: Dimensionality of each data point\n",
    "* `step`: Granularity of skips. The lower the number, the noisier. The higher the number, the more erratic.\n",
    "\n",
    "Take note we also capture the predicted character for the given sentence. This will allow us to setup the data in such a way that a given set of sequences predicts the next character. In machine learning, we will denote this as our `y` value or ground truth. Each `y` however is represented as a one hot encoding where a position will receive a value of `1` depending on the character position in `word_indices`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 10\n",
    "step = 5\n",
    "\n",
    "sentences = []\n",
    "next_words = []\n",
    "\n",
    "for i in range(0, len(lemmatized_tokens) - maxlen, step):\n",
    "    sentences.append(lemmatized_tokens[i: i+maxlen])\n",
    "    next_words.append(lemmatized_tokens[i + maxlen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['life',\n",
       "  'remember',\n",
       "  'helped',\n",
       "  'forgot',\n",
       "  'escape',\n",
       "  'quite',\n",
       "  'chance',\n",
       "  'came',\n",
       "  'grow',\n",
       "  'watch'],\n",
       " ['quite',\n",
       "  'chance',\n",
       "  'came',\n",
       "  'grow',\n",
       "  'watch',\n",
       "  'killed',\n",
       "  'knew',\n",
       "  'dream',\n",
       "  'raised',\n",
       "  'showing'],\n",
       " ['killed',\n",
       "  'knew',\n",
       "  'dream',\n",
       "  'raised',\n",
       "  'showing',\n",
       "  'mirror',\n",
       "  'stop',\n",
       "  'made',\n",
       "  'flow',\n",
       "  'one'],\n",
       " ['mirror',\n",
       "  'stop',\n",
       "  'made',\n",
       "  'flow',\n",
       "  'one',\n",
       "  'time',\n",
       "  'many',\n",
       "  'seems',\n",
       "  'always',\n",
       "  'end'],\n",
       " ['time',\n",
       "  'many',\n",
       "  'seems',\n",
       "  'always',\n",
       "  'end',\n",
       "  'better',\n",
       "  'practicing',\n",
       "  'reality',\n",
       "  'role',\n",
       "  ','],\n",
       " ['better',\n",
       "  'practicing',\n",
       "  'reality',\n",
       "  'role',\n",
       "  ',',\n",
       "  'perform',\n",
       "  'neighborhood',\n",
       "  'front',\n",
       "  'fulfill',\n",
       "  'achieved'],\n",
       " ['perform',\n",
       "  'neighborhood',\n",
       "  'front',\n",
       "  'fulfill',\n",
       "  'achieved',\n",
       "  'named',\n",
       "  'beat',\n",
       "  'kid',\n",
       "  'world',\n",
       "  'strife'],\n",
       " ['named',\n",
       "  'beat',\n",
       "  'kid',\n",
       "  'world',\n",
       "  'strife',\n",
       "  'hard',\n",
       "  'rapper',\n",
       "  'successful',\n",
       "  'would',\n",
       "  'boy'],\n",
       " ['hard',\n",
       "  'rapper',\n",
       "  'successful',\n",
       "  'would',\n",
       "  'boy',\n",
       "  'mood',\n",
       "  'finally',\n",
       "  'hood',\n",
       "  'rap',\n",
       "  'rage'],\n",
       " ['mood',\n",
       "  'finally',\n",
       "  'hood',\n",
       "  'rap',\n",
       "  'rage',\n",
       "  'writing',\n",
       "  'top',\n",
       "  'love',\n",
       "  'upon',\n",
       "  'circumstance'],\n",
       " ['writing',\n",
       "  'top',\n",
       "  'love',\n",
       "  'upon',\n",
       "  'circumstance',\n",
       "  'model',\n",
       "  'chase',\n",
       "  'crowd',\n",
       "  'rhyme',\n",
       "  'faced'],\n",
       " ['model',\n",
       "  'chase',\n",
       "  'crowd',\n",
       "  'rhyme',\n",
       "  'faced',\n",
       "  'stage',\n",
       "  'change',\n",
       "  'struggle',\n",
       "  'day',\n",
       "  'lyric'],\n",
       " ['stage',\n",
       "  'change',\n",
       "  'struggle',\n",
       "  'day',\n",
       "  'lyric',\n",
       "  'mike',\n",
       "  'troubled',\n",
       "  'growing',\n",
       "  'started',\n",
       "  'never'],\n",
       " ['mike',\n",
       "  'troubled',\n",
       "  'growing',\n",
       "  'started',\n",
       "  'never',\n",
       "  'make',\n",
       "  'see',\n",
       "  'could',\n",
       "  'music',\n",
       "  'dream']]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['killed',\n",
       " 'mirror',\n",
       " 'time',\n",
       " 'better',\n",
       " 'perform',\n",
       " 'named',\n",
       " 'hard',\n",
       " 'mood',\n",
       " 'writing',\n",
       " 'model',\n",
       " 'stage',\n",
       " 'mike',\n",
       " 'make',\n",
       " 'work']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization\n",
    "\n",
    "This step simply converts the `sentences` and `next_words` to its `x` and `y` components respectively. Since we're using pytorch, we convert it to a tensor. Succeeding cells check the shape of `x` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization\n"
     ]
    }
   ],
   "source": [
    "print(\"Vectorization\")\n",
    "device = 'cpu'\n",
    "x = np.zeros((len(sentences), maxlen, len(words)), dtype=np.float64)\n",
    "y = np.zeros((len(sentences), len(words)), dtype=np.float64)\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, word, in enumerate(sentence):\n",
    "        x[i, t, word_indices[word]] = 1\n",
    "    y[i, word_indices[next_words[i]]] = 1\n",
    "    \n",
    "x = torch.tensor(x).float().to(device)\n",
    "y = torch.tensor(y).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 10, 77])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 770])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.flatten(x, start_dim=1)\n",
    "\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 77])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Function for Generating Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callback Function\n",
    "\n",
    "This generates sample text from a given seed and ran for every epoch of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callback(model):\n",
    "    start = 0\n",
    "    stop = len(lemmatized_tokens) - maxlen - 1\n",
    "\n",
    "    #print(\"Start: {}\".format(start))\n",
    "    #print(\"Stop: {}\".format(stop))\n",
    "\n",
    "    start_index = random.randint(start, stop)\n",
    "\n",
    "    #print(\"Start Index: {}\".format(start_index))\n",
    "\n",
    "    sentence = lemmatized_tokens[start_index: start_index + maxlen]\n",
    "\n",
    "    #print(\"Sentence: {}\".format(sentence))\n",
    "    #print(\"Sentence Length: {}\".format(len(sentence)))\n",
    "\n",
    "    generated = \"\"\n",
    "\n",
    "    for i in range(400):\n",
    "        x_predictions = np.zeros((1, maxlen, len(words)))\n",
    "\n",
    "        for t, w in enumerate(sentence):\n",
    "            #print(\"Sentence t: {}\".format(t))\n",
    "            #print(\"Sentence w: {}\".format(w))\n",
    "            #print(\"x_predictions[0, t, word_indices[w]]: {}\".format(x_predictions[0, t, word_indices[w]]))\n",
    "            x_predictions[0, t, word_indices[w]] = 1\n",
    "\n",
    "            #print(x_predictions)\n",
    "        x_predictions = torch.tensor(x_predictions).float().to(device)\n",
    "        x = torch.flatten(x_predictions, start_dim=1)\n",
    "\n",
    "        preds = model.forward(x)[0].detach().cpu().numpy()\n",
    "\n",
    "        next_index = sample(preds)\n",
    "        #print(\"next_index: {}\".format(next_index))\n",
    "        next_word = indices_words[next_index]\n",
    "        #print(\"next_word: {}\".format(next_word))\n",
    "\n",
    "        generated += next_word\n",
    "        #print(\"generated with next_word: {}\".format(generated))\n",
    "        sentence = sentence[1:]\n",
    "        sentence.append(next_word)\n",
    "        #print(\"sentence with next_word: {}\".format(sentence))\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultiLayerPerceptron Model\n",
    "\n",
    "This will be our current language model. Although originally used for classification, we can also treat is a regression model since our ground truth represents the next predicted character in a sequence. Take note that this is a rather simplistic model without any properties to remember previous input. This forces the model to treat each input as an independent observation without considering sequential behavior. TLDR, it won't generate good results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden = nn.Linear(input_dim, 500)\n",
    "        self.output = nn.Linear(500, output_dim)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # f(x) = a(f(x))\n",
    "        x = self.relu(self.hidden(x))\n",
    "        y = self.sigmoid(self.output(x))\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiLayerPerceptron(\n",
       "  (hidden): Linear(in_features=770, out_features=500, bias=True)\n",
       "  (output): Linear(in_features=500, out_features=77, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultiLayerPerceptron(x.shape[1], y.shape[1]).to(device)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Ave Loss: 4.343805858067104\n",
      "Generated sentence:\n",
      "['make', 'music', ',', 'top', 'grow', 'successful', 'beyond', 'writing', 'beat', 'beyond']\n",
      "Length: 10\n",
      "Epoch: 1\n",
      "Ave Loss: 4.343792847224644\n",
      "Generated sentence:\n",
      "['rage', 'rise', 'work', 'started', 'end', 'hood', 'escape', 'quite', 'stage', 'see']\n",
      "Length: 10\n",
      "Epoch: 2\n",
      "Ave Loss: 4.343780653817313\n",
      "Generated sentence:\n",
      "['dream', 'role', 'model', 'love', 'beyond', 'showing', 'mirror', 'chance', 'could', 'hood']\n",
      "Length: 10\n",
      "Epoch: 3\n",
      "Ave Loss: 4.34376859664917\n",
      "Generated sentence:\n",
      "['named', 'achieved', 'stop', 'dream', 'struggle', 'never', 'remember', 'watch', 'role', 'upon']\n",
      "Length: 10\n",
      "Epoch: 4\n",
      "Ave Loss: 4.343756301062448\n",
      "Generated sentence:\n",
      "['hard', 'music', 'hood', 'quite', 'grow', 'knew', 'kid', 'rap', 'chase', 'see']\n",
      "Length: 10\n",
      "Epoch: 5\n",
      "Ave Loss: 4.3437440395355225\n",
      "Generated sentence:\n",
      "['perform', 'raised', 'world', 'quite', 'love', 'raised', 'world', 'escape', 'rap', 'time']\n",
      "Length: 10\n",
      "Epoch: 6\n",
      "Ave Loss: 4.343731948307583\n",
      "Generated sentence:\n",
      "['music', 'beat', 'beat', 'neighborhood', 'role', 'growing', 'crowd', 'stage', 'rap', 'boy']\n",
      "Length: 10\n",
      "Epoch: 7\n",
      "Ave Loss: 4.343719584601266\n",
      "Generated sentence:\n",
      "['front', 'rap', 'chase', 'see', 'many', 'work', 'boy', 'would', 'life', 'started']\n",
      "Length: 10\n",
      "Epoch: 8\n",
      "Ave Loss: 4.343707323074341\n",
      "Generated sentence:\n",
      "['mike', 'achieved', 'day', 'change', 'hard', 'achieved', 'knew', 'growing', 'boy', 'time']\n",
      "Length: 10\n",
      "Epoch: 9\n",
      "Ave Loss: 4.3436949253082275\n",
      "Generated sentence:\n",
      "['named', 'rapper', 'work', 'mike', 'growing', 'front', 'day', 'grow', 'many', 'faced']\n",
      "Length: 10\n",
      "Epoch: 10\n",
      "Ave Loss: 4.343682663781302\n",
      "Generated sentence:\n",
      "['remember', 'faced', 'stage', 'could', 'rap', 'beat', 'mirror', 'grow', 'role', 'made']\n",
      "Length: 10\n",
      "Epoch: 11\n",
      "Ave Loss: 4.343670266015189\n",
      "Generated sentence:\n",
      "['many', 'practicing', 'remember', 'rap', 'better', 'never', 'see', 'mirror', 'started', 'lyric']\n",
      "Length: 10\n",
      "Epoch: 12\n",
      "Ave Loss: 4.343657868249076\n",
      "Generated sentence:\n",
      "['one', 'escape', 'successful', 'model', 'see', 'crowd', 'would', 'stop', 'end', 'strife']\n",
      "Length: 10\n",
      "Epoch: 13\n",
      "Ave Loss: 4.343645436423166\n",
      "Generated sentence:\n",
      "['successful', ',', 'named', 'showing', 'started', 'stage', 'role', 'rapper', 'came', 'troubled']\n",
      "Length: 10\n",
      "Epoch: 14\n",
      "Ave Loss: 4.3436330045972555\n",
      "Generated sentence:\n",
      "['could', 'better', 'strife', 'stop', 'day', 'beyond', 'rap', 'role', 'rage', 'successful']\n",
      "Length: 10\n",
      "Epoch: 15\n",
      "Ave Loss: 4.343620504651751\n",
      "Generated sentence:\n",
      "['work', 'boy', 'watch', 'rhyme', 'watch', 'one', 'front', 'beyond', 'could', 'kid']\n",
      "Length: 10\n",
      "Epoch: 16\n",
      "Ave Loss: 4.343608106885638\n",
      "Generated sentence:\n",
      "['crowd', 'raised', 'see', 'crowd', 'end', 'dream', 'came', 'chase', 'hood', 'writing']\n",
      "Length: 10\n",
      "Epoch: 17\n",
      "Ave Loss: 4.343595606940133\n",
      "Generated sentence:\n",
      "['writing', 'beat', 'watch', 'knew', 'killed', 'showing', 'time', 'top', 'love', 'upon']\n",
      "Length: 10\n",
      "Epoch: 18\n",
      "Ave Loss: 4.343583072934832\n",
      "Generated sentence:\n",
      "['perform', 'showing', 'started', 'grow', 'upon', 'chase', 'remember', 'upon', 'mirror', 'came']\n",
      "Length: 10\n",
      "Epoch: 19\n",
      "Ave Loss: 4.3435704708099365\n",
      "Generated sentence:\n",
      "['neighborhood', 'end', 'rage', 'chase', 'growing', 'boy', 'stop', 'rhyme', 'crowd', 'mirror']\n",
      "Length: 10\n",
      "Epoch: 20\n",
      "Ave Loss: 4.3435579027448386\n",
      "Generated sentence:\n",
      "['quite', 'achieved', 'end', 'rhyme', 'upon', 'mike', 'successful', 'troubled', 'writing', 'forgot']\n",
      "Length: 10\n",
      "Epoch: 21\n",
      "Ave Loss: 4.343545266560146\n",
      "Generated sentence:\n",
      "['mood', 'dream', 'never', 'troubled', 'started', 'stage', 'role', 'would', 'rap', 'started']\n",
      "Length: 10\n",
      "Epoch: 22\n",
      "Ave Loss: 4.343532698495047\n",
      "Generated sentence:\n",
      "['chance', 'front', 'named', 'struggle', 'remember', 'raised', 'raised', 'writing', 'hard', 'named']\n",
      "Length: 10\n",
      "Epoch: 23\n",
      "Ave Loss: 4.343519960130964\n",
      "Generated sentence:\n",
      "['helped', 'boy', 'mood', 'work', 'upon', 'escape', 'flow', 'perform', 'achieved', 'rap']\n",
      "Length: 10\n",
      "Epoch: 24\n",
      "Ave Loss: 4.34350722176688\n",
      "Generated sentence:\n",
      "['boy', 'better', 'writing', 'world', 'top', 'role', 'knew', 'helped', 'hood', 'started']\n",
      "Length: 10\n",
      "Epoch: 25\n",
      "Ave Loss: 4.343494449343\n",
      "Generated sentence:\n",
      "['make', 'see', 'always', 'upon', 'neighborhood', 'day', 'raised', 'day', 'writing', 'grow']\n",
      "Length: 10\n",
      "Epoch: 26\n",
      "Ave Loss: 4.343481574739728\n",
      "Generated sentence:\n",
      "['escape', 'neighborhood', 'rap', 'chance', 'world', 'work', 'named', 'watch', 'rage', 'rhyme']\n",
      "Length: 10\n",
      "Epoch: 27\n",
      "Ave Loss: 4.343468768256051\n",
      "Generated sentence:\n",
      "['love', 'make', 'perform', 'fulfill', 'chase', 'hood', 'remember', 'change', 'achieved', 'better']\n",
      "Length: 10\n",
      "Epoch: 28\n",
      "Ave Loss: 4.343455825533185\n",
      "Generated sentence:\n",
      "['grow', 'killed', ',', 'chance', 'kid', 'would', 'end', 'circumstance', 'top', 'rhyme']\n",
      "Length: 10\n",
      "Epoch: 29\n",
      "Ave Loss: 4.34344288281032\n",
      "Generated sentence:\n",
      "['top', 'rap', 'growing', 'hood', 'change', 'always', 'chance', 'one', 'crowd', ',']\n",
      "Length: 10\n",
      "Epoch: 30\n",
      "Ave Loss: 4.343429871967861\n",
      "Generated sentence:\n",
      "['rap', 'would', 'make', 'many', 'never', 'stop', 'top', 'many', 'rapper', 'showing']\n",
      "Length: 10\n",
      "Epoch: 31\n",
      "Ave Loss: 4.343416827065604\n",
      "Generated sentence:\n",
      "['practicing', 'named', 'started', 'seems', 'came', 'named', 'finally', 'day', 'made', 'successful']\n",
      "Length: 10\n",
      "Epoch: 32\n",
      "Ave Loss: 4.34340374810355\n",
      "Generated sentence:\n",
      "['see', 'helped', 'raised', 'world', 'chance', 'mirror', 'hood', 'watch', 'end', 'mike']\n",
      "Length: 10\n",
      "Epoch: 33\n",
      "Ave Loss: 4.343390532902309\n",
      "Generated sentence:\n",
      "['change', 'make', 'came', 'practicing', 'dream', 'knew', 'role', 'time', 'upon', 'rap']\n",
      "Length: 10\n",
      "Epoch: 34\n",
      "Ave Loss: 4.343377351760864\n",
      "Generated sentence:\n",
      "['work', 'raised', 'hood', 'mike', 'hood', 'achieved', 'started', 'faced', 'time', 'forgot']\n",
      "Length: 10\n",
      "Epoch: 35\n",
      "Ave Loss: 4.3433641365596225\n",
      "Generated sentence:\n",
      "['model', 'chase', 'always', 'rap', 'could', 'rapper', 'grow', 'escape', 'rhyme', 'end']\n",
      "Length: 10\n",
      "Epoch: 36\n",
      "Ave Loss: 4.343350751059396\n",
      "Generated sentence:\n",
      "['remember', 'killed', 'stop', 'rapper', 'stage', 'came', 'music', 'helped', 'struggle', 'better']\n",
      "Length: 10\n",
      "Epoch: 37\n",
      "Ave Loss: 4.3433375017983575\n",
      "Generated sentence:\n",
      "['troubled', ',', 'stop', 'named', 'watch', 'named', 'better', 'achieved', 'named', 'see']\n",
      "Length: 10\n",
      "Epoch: 38\n",
      "Ave Loss: 4.343323980058942\n",
      "Generated sentence:\n",
      "['escape', 'upon', 'lyric', 'rage', 'escape', 'seems', 'always', 'showing', 'stage', 'perform']\n",
      "Length: 10\n",
      "Epoch: 39\n",
      "Ave Loss: 4.343310628618513\n",
      "Generated sentence:\n",
      "['circumstance', 'faced', 'work', 'mirror', 'fulfill', 'forgot', 'rise', 'achieved', 'life', 'quite']\n",
      "Length: 10\n",
      "Epoch: 40\n",
      "Ave Loss: 4.343297140938895\n",
      "Generated sentence:\n",
      "['role', 'started', 'strife', 'make', 'troubled', 'growing', 'mood', 'knew', 'quite', 'reality']\n",
      "Length: 10\n",
      "Epoch: 41\n",
      "Ave Loss: 4.343283619199481\n",
      "Generated sentence:\n",
      "['finally', 'rap', 'mike', 'rise', 'upon', 'grow', 'raised', 'faced', 'showing', 'crowd']\n",
      "Length: 10\n",
      "Epoch: 42\n",
      "Ave Loss: 4.343269927161081\n",
      "Generated sentence:\n",
      "['many', 'better', 'kid', 'love', 'mood', 'world', 'day', 'forgot', 'seems', 'came']\n",
      "Length: 10\n",
      "Epoch: 43\n",
      "Ave Loss: 4.343256269182477\n",
      "Generated sentence:\n",
      "['forgot', 'showing', 'change', 'reality', 'rhyme', 'made', 'mood', 'beyond', 'rap', 'achieved']\n",
      "Length: 10\n",
      "Epoch: 44\n",
      "Ave Loss: 4.3432425771440775\n",
      "Generated sentence:\n",
      "['day', 'one', 'beat', 'change', 'rap', 'writing', 'rap', 'helped', 'named', 'reality']\n",
      "Length: 10\n",
      "Epoch: 45\n",
      "Ave Loss: 4.343228782926287\n",
      "Generated sentence:\n",
      "['world', 'remember', 'stop', 'make', 'reality', 'knew', 'perform', 'hard', 'see', 'would']\n",
      "Length: 10\n",
      "Epoch: 46\n",
      "Ave Loss: 4.3432150568280905\n",
      "Generated sentence:\n",
      "['front', 'writing', 'would', 'better', 'practicing', 'never', 'would', 'top', 'stage', 'time']\n",
      "Length: 10\n",
      "Epoch: 47\n",
      "Ave Loss: 4.343201126371111\n",
      "Generated sentence:\n",
      "['mood', 'many', 'reality', 'see', 'lyric', 'killed', 'remember', 'role', 'never', 'remember']\n",
      "Length: 10\n",
      "Epoch: 48\n",
      "Ave Loss: 4.343187093734741\n",
      "Generated sentence:\n",
      "['hard', 'quite', 'quite', 'achieved', 'lyric', 'hard', 'showing', 'successful', 'rapper', 'mirror']\n",
      "Length: 10\n",
      "Epoch: 49\n",
      "Ave Loss: 4.343173265457153\n",
      "Generated sentence:\n",
      "['day', 'strife', 'reality', 'forgot', 'beyond', 'rhyme', 'reality', 'beat', 'fulfill', 'top']\n",
      "Length: 10\n",
      "Epoch: 50\n",
      "Ave Loss: 4.343159198760986\n",
      "Generated sentence:\n",
      "['front', 'work', 'world', 'boy', 'one', 'mirror', 'practicing', 'music', 'watch', 'kid']\n",
      "Length: 10\n",
      "Epoch: 51\n",
      "Ave Loss: 4.343145098005023\n",
      "Generated sentence:\n",
      "['change', 'escape', 'rap', 'end', 'writing', 'end', 'upon', 'hard', 'mood', 'work']\n",
      "Length: 10\n",
      "Epoch: 52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 4.343130929129464\n",
      "Generated sentence:\n",
      "['killed', 'role', 'rise', 'front', 'showing', 'rise', 'rise', 'writing', 'mood', 'world']\n",
      "Length: 10\n",
      "Epoch: 53\n",
      "Ave Loss: 4.343116760253906\n",
      "Generated sentence:\n",
      "['writing', 'work', 'hard', 'stage', 'work', 'quite', 'rage', 'rise', 'music', 'troubled']\n",
      "Length: 10\n",
      "Epoch: 54\n",
      "Ave Loss: 4.343102523258755\n",
      "Generated sentence:\n",
      "['love', 'one', 'rhyme', 'growing', 'troubled', 'change', 'growing', ',', 'growing', 'music']\n",
      "Length: 10\n",
      "Epoch: 55\n",
      "Ave Loss: 4.343088150024414\n",
      "Generated sentence:\n",
      "['dream', 'achieved', 'hard', 'role', 'watch', 'could', 'raised', 'always', 'beat', 'faced']\n",
      "Length: 10\n",
      "Epoch: 56\n",
      "Ave Loss: 4.343073776790074\n",
      "Generated sentence:\n",
      "['always', 'lyric', 'upon', 'knew', 'finally', 'lyric', 'model', 'hard', 'upon', 'time']\n",
      "Length: 10\n",
      "Epoch: 57\n",
      "Ave Loss: 4.343059233256748\n",
      "Generated sentence:\n",
      "['stage', 'rhyme', 'remember', 'escape', 'watch', 'struggle', 'chance', 'could', 'grow', 'hood']\n",
      "Length: 10\n",
      "Epoch: 58\n",
      "Ave Loss: 4.343044655663626\n",
      "Generated sentence:\n",
      "['kid', 'grow', 'faced', 'make', 'troubled', 'faced', 'one', 'beat', 'successful', 'rhyme']\n",
      "Length: 10\n",
      "Epoch: 59\n",
      "Ave Loss: 4.34303000995091\n",
      "Generated sentence:\n",
      "['boy', 'chance', 'many', 'finally', ',', 'writing', 'growing', 'better', 'life', 'mirror']\n",
      "Length: 10\n",
      "Epoch: 60\n",
      "Ave Loss: 4.343015398297991\n",
      "Generated sentence:\n",
      "['mirror', 'could', 'lyric', 'faced', 'rapper', 'circumstance', 'music', 'faced', 'stop', 'perform']\n",
      "Length: 10\n",
      "Epoch: 61\n",
      "Ave Loss: 4.343000650405884\n",
      "Generated sentence:\n",
      "['quite', 'stage', 'achieved', 'life', 'perform', 'rage', 'many', 'love', 'kid', 'raised']\n",
      "Length: 10\n",
      "Epoch: 62\n",
      "Ave Loss: 4.342985902513776\n",
      "Generated sentence:\n",
      "['hood', 'knew', 'rhyme', 'seems', 'achieved', 'killed', 'stage', 'life', 'writing', 'dream']\n",
      "Length: 10\n",
      "Epoch: 63\n",
      "Ave Loss: 4.342970984322684\n",
      "Generated sentence:\n",
      "['kid', 'neighborhood', 'named', 'grow', 'rhyme', 'kid', 'knew', 'love', 'mood', 'perform']\n",
      "Length: 10\n",
      "Epoch: 64\n",
      "Ave Loss: 4.342955998011997\n",
      "Generated sentence:\n",
      "['rise', 'see', ',', 'quite', 'knew', 'hard', 'came', 'day', 'started', 'troubled']\n",
      "Length: 10\n",
      "Epoch: 65\n",
      "Ave Loss: 4.342940807342529\n",
      "Generated sentence:\n",
      "['chance', 'see', 'kid', 'faced', 'day', 'role', 'rhyme', 'successful', 'work', 'chase']\n",
      "Length: 10\n",
      "Epoch: 66\n",
      "Ave Loss: 4.342925650732858\n",
      "Generated sentence:\n",
      "['made', 'achieved', 'practicing', 'perform', 'work', 'love', 'day', 'writing', 'mood', 'achieved']\n",
      "Length: 10\n",
      "Epoch: 67\n",
      "Ave Loss: 4.342910426003592\n",
      "Generated sentence:\n",
      "['boy', 'beat', 'made', 'model', 'crowd', 'role', 'love', 'mike', 'fulfill', 'escape']\n",
      "Length: 10\n",
      "Epoch: 68\n",
      "Ave Loss: 4.342895099094936\n",
      "Generated sentence:\n",
      "['world', 'made', 'mike', 'always', 'make', 'raised', 'quite', 'dream', 'chase', 'mood']\n",
      "Length: 10\n",
      "Epoch: 69\n",
      "Ave Loss: 4.342879601887295\n",
      "Generated sentence:\n",
      "['change', 'reality', 'role', 'front', 'better', 'named', 'hard', 'boy', 'one', 'lyric']\n",
      "Length: 10\n",
      "Epoch: 70\n",
      "Ave Loss: 4.34286413873945\n",
      "Generated sentence:\n",
      "['stop', 'chance', 'change', 'reality', 'role', ',', 'many', 'beyond', 'watch', 'fulfill']\n",
      "Length: 10\n",
      "Epoch: 71\n",
      "Ave Loss: 4.342848607472011\n",
      "Generated sentence:\n",
      "['named', 'make', 'faced', 'killed', 'stage', 'achieved', 'mood', 'chase', 'life', 'one']\n",
      "Length: 10\n",
      "Epoch: 72\n",
      "Ave Loss: 4.342833008084979\n",
      "Generated sentence:\n",
      "['stage', 'stop', 'reality', 'crowd', 'raised', 'chase', 'better', 'helped', 'end', 'rapper']\n",
      "Length: 10\n",
      "Epoch: 73\n",
      "Ave Loss: 4.3428172043391635\n",
      "Generated sentence:\n",
      "['rage', 'one', 'practicing', 'beat', 'end', 'troubled', 'practicing', 'top', 'crowd', 'rise']\n",
      "Length: 10\n",
      "Epoch: 74\n",
      "Ave Loss: 4.342801400593349\n",
      "Generated sentence:\n",
      "['never', 'perform', 'day', 'hood', 'raised', 'remember', 'beat', 'struggle', 'top', 'stage']\n",
      "Length: 10\n",
      "Epoch: 75\n",
      "Ave Loss: 4.34278552872794\n",
      "Generated sentence:\n",
      "['stop', 'day', 'showing', 'chase', 'forgot', 'day', 'reality', 'showing', 'stop', 'one']\n",
      "Length: 10\n",
      "Epoch: 76\n",
      "Ave Loss: 4.342769588742938\n",
      "Generated sentence:\n",
      "['struggle', 'better', 'struggle', 'beyond', 'remember', 'rapper', 'life', 'reality', 'work', 'kid']\n",
      "Length: 10\n",
      "Epoch: 77\n",
      "Ave Loss: 4.342753648757935\n",
      "Generated sentence:\n",
      "['helped', 'stop', 'mirror', 'life', 'world', 'quite', 'work', 'neighborhood', 'escape', 'life']\n",
      "Length: 10\n",
      "Epoch: 78\n",
      "Ave Loss: 4.342737470354352\n",
      "Generated sentence:\n",
      "['time', 'always', 'role', 'always', 'named', 'see', 'never', 'killed', 'see', 'faced']\n",
      "Length: 10\n",
      "Epoch: 79\n",
      "Ave Loss: 4.3427212578909735\n",
      "Generated sentence:\n",
      "['model', 'raised', 'rap', 'writing', 'mike', 'came', 'always', 'troubled', 'never', 'many']\n",
      "Length: 10\n",
      "Epoch: 80\n",
      "Ave Loss: 4.342705045427595\n",
      "Generated sentence:\n",
      "['knew', 'would', 'circumstance', 'dream', 'writing', 'seems', 'would', 'could', 'raised', 'beyond']\n",
      "Length: 10\n",
      "Epoch: 81\n",
      "Ave Loss: 4.342688594545637\n",
      "Generated sentence:\n",
      "['day', 'killed', 'reality', 'successful', 'mike', 'would', 'rhyme', 'lyric', 'make', 'stop']\n",
      "Length: 10\n",
      "Epoch: 82\n",
      "Ave Loss: 4.342672177723476\n",
      "Generated sentence:\n",
      "['escape', 'beat', 'troubled', 'beyond', 'started', ',', 'many', 'reality', 'many', 'escape']\n",
      "Length: 10\n",
      "Epoch: 83\n",
      "Ave Loss: 4.342655658721924\n",
      "Generated sentence:\n",
      "['boy', 'hard', 'fulfill', 'forgot', 'upon', 'reality', 'helped', 'perform', 'fulfill', 'rapper']\n",
      "Length: 10\n",
      "Epoch: 84\n",
      "Ave Loss: 4.342639071600778\n",
      "Generated sentence:\n",
      "['front', 'could', 'circumstance', 'boy', 'knew', 'rap', 'chance', 'hard', 'chase', 'practicing']\n",
      "Length: 10\n",
      "Epoch: 85\n",
      "Ave Loss: 4.342622382300241\n",
      "Generated sentence:\n",
      "['rise', 'stage', 'quite', 'flow', 'work', 'better', 'flow', 'came', 'writing', 'world']\n",
      "Length: 10\n",
      "Epoch: 86\n",
      "Ave Loss: 4.342605522700718\n",
      "Generated sentence:\n",
      "['neighborhood', 'growing', 'day', 'beat', 'helped', 'grow', 'successful', 'rapper', 'practicing', 'lyric']\n",
      "Length: 10\n",
      "Epoch: 87\n",
      "Ave Loss: 4.342588663101196\n",
      "Generated sentence:\n",
      "['neighborhood', 'finally', 'top', 'hard', 'crowd', 'mood', 'better', 'end', 'model', 'music']\n",
      "Length: 10\n",
      "Epoch: 88\n",
      "Ave Loss: 4.342571633202689\n",
      "Generated sentence:\n",
      "['made', 'boy', 'flow', 'top', 'raised', 'mike', 'many', 'never', 'rise', 'rap']\n",
      "Length: 10\n",
      "Epoch: 89\n",
      "Ave Loss: 4.34255450112479\n",
      "Generated sentence:\n",
      "['model', 'mood', 'growing', 'love', 'world', 'started', ',', 'change', 'dream', 'remember']\n",
      "Length: 10\n",
      "Epoch: 90\n",
      "Ave Loss: 4.3425374031066895\n",
      "Generated sentence:\n",
      "['upon', 'beat', 'raised', 'beat', 'music', 'writing', 'stop', 'make', 'neighborhood', 'knew']\n",
      "Length: 10\n",
      "Epoch: 91\n",
      "Ave Loss: 4.342520100729806\n",
      "Generated sentence:\n",
      "['end', 'rhyme', 'crowd', 'mirror', 'successful', 'work', 'hood', 'one', 'killed', 'growing']\n",
      "Length: 10\n",
      "Epoch: 92\n",
      "Ave Loss: 4.342502764293125\n",
      "Generated sentence:\n",
      "['practicing', 'lyric', 'stop', 'struggle', ',', 'one', 'rhyme', 'rapper', 'practicing', 'life']\n",
      "Length: 10\n",
      "Epoch: 93\n",
      "Ave Loss: 4.342485223497663\n",
      "Generated sentence:\n",
      "['troubled', 'rap', 'dream', 'rise', 'rage', 'chance', 'music', 'troubled', 'rap', 'faced']\n",
      "Length: 10\n",
      "Epoch: 94\n",
      "Ave Loss: 4.342467648642404\n",
      "Generated sentence:\n",
      "['kid', 'struggle', 'hood', 'crowd', 'chase', 'remember', 'fulfill', 'raised', 'made', 'rap']\n",
      "Length: 10\n",
      "Epoch: 95\n",
      "Ave Loss: 4.342449971607754\n",
      "Generated sentence:\n",
      "['strife', 'lyric', 'boy', 'mood', 'quite', 'better', 'role', 'strife', 'rhyme', 'strife']\n",
      "Length: 10\n",
      "Epoch: 96\n",
      "Ave Loss: 4.342432192393711\n",
      "Generated sentence:\n",
      "['hood', 'mike', 'troubled', 'reality', 'world', 'came', 'watch', 'music', 'chance', 'quite']\n",
      "Length: 10\n",
      "Epoch: 97\n",
      "Ave Loss: 4.342414208820888\n",
      "Generated sentence:\n",
      "['raised', 'rhyme', 'killed', 'showing', 'chance', 'made', 'seems', 'lyric', 'forgot', 'music']\n",
      "Length: 10\n",
      "Epoch: 98\n",
      "Ave Loss: 4.342396259307861\n",
      "Generated sentence:\n",
      "['hard', 'flow', 'boy', 'crowd', 'love', 'rise', 'rage', 'chance', 'beat', 'made']\n",
      "Length: 10\n",
      "Epoch: 99\n",
      "Ave Loss: 4.342378173555646\n",
      "Generated sentence:\n",
      "['love', 'remember', 'neighborhood', 'crowd', 'growing', 'always', 'mike', 'chase', 'could', 'reality']\n",
      "Length: 10\n",
      "Epoch: 100\n",
      "Ave Loss: 4.342359849384853\n",
      "Generated sentence:\n",
      "['boy', 'life', 'flow', 'strife', 'perform', 'upon', 'rise', 'successful', 'practicing', 'boy']\n",
      "Length: 10\n",
      "Epoch: 101\n",
      "Ave Loss: 4.342341491154262\n",
      "Generated sentence:\n",
      "['practicing', 'flow', 'hood', 'mood', 'came', 'could', 'love', 'neighborhood', 'writing', 'faced']\n",
      "Length: 10\n",
      "Epoch: 102\n",
      "Ave Loss: 4.342323098863874\n",
      "Generated sentence:\n",
      "['hard', 'end', 'beyond', 'escape', 'always', 'strife', 'troubled', 'rage', 'see', 'top']\n",
      "Length: 10\n",
      "Epoch: 103\n",
      "Ave Loss: 4.342304502214704\n",
      "Generated sentence:\n",
      "['showing', 'quite', 'lyric', 'day', 'boy', 'top', 'fulfill', 'make', 'stage', 'flow']\n",
      "Length: 10\n",
      "Epoch: 104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave Loss: 4.342285735266549\n",
      "Generated sentence:\n",
      "['change', 'watch', 'stop', 'kid', 'see', 'top', 'world', ',', 'mirror', 'boy']\n",
      "Length: 10\n",
      "Epoch: 105\n",
      "Ave Loss: 4.342267036437988\n",
      "Generated sentence:\n",
      "['life', 'came', 'chance', 'achieved', 'quite', 'would', 'struggle', 'made', 'named', 'hood']\n",
      "Length: 10\n",
      "Epoch: 106\n",
      "Ave Loss: 4.342248133250645\n",
      "Generated sentence:\n",
      "['growing', 'music', 'successful', 'killed', 'work', 'reality', 'end', 'hood', 'fulfill', 'see']\n",
      "Length: 10\n",
      "Epoch: 107\n",
      "Ave Loss: 4.342229127883911\n",
      "Generated sentence:\n",
      "['growing', 'one', 'would', 'finally', 'finally', 'lyric', 'rise', 'raised', 'world', 'strife']\n",
      "Length: 10\n",
      "Epoch: 108\n",
      "Ave Loss: 4.342209952218192\n",
      "Generated sentence:\n",
      "['made', 'mike', 'better', 'mirror', 'end', 'upon', 'music', 'rise', 'crowd', 'world']\n",
      "Length: 10\n",
      "Epoch: 109\n",
      "Ave Loss: 4.342190844672067\n",
      "Generated sentence:\n",
      "['forgot', 'quite', 'music', 'love', 'fulfill', 'quite', 'kid', 'troubled', 'day', 'escape']\n",
      "Length: 10\n",
      "Epoch: 110\n",
      "Ave Loss: 4.342171464647565\n",
      "Generated sentence:\n",
      "['mike', 'mood', 'forgot', 'rage', 'one', 'top', 'writing', 'watch', 'knew', 'came']\n",
      "Length: 10\n",
      "Epoch: 111\n",
      "Ave Loss: 4.342151982443673\n",
      "Generated sentence:\n",
      "['flow', 'troubled', 'end', 'troubled', 'writing', 'showing', 'hood', 'perform', 'mood', 'day']\n",
      "Length: 10\n",
      "Epoch: 112\n",
      "Ave Loss: 4.342132534299578\n",
      "Generated sentence:\n",
      "['one', 'front', 'music', 'hood', 'world', 'chase', 'troubled', 'role', 'started', 'remember']\n",
      "Length: 10\n",
      "Epoch: 113\n",
      "Ave Loss: 4.342112847736904\n",
      "Generated sentence:\n",
      "['stage', 'mike', 'music', 'struggle', 'successful', 'crowd', 'made', 'made', 'started', 'strife']\n",
      "Length: 10\n",
      "Epoch: 114\n",
      "Ave Loss: 4.342093161174229\n",
      "Generated sentence:\n",
      "['successful', 'started', 'rap', 'stage', 'always', 'would', 'quite', 'crowd', 'helped', 'named']\n",
      "Length: 10\n",
      "Epoch: 115\n",
      "Ave Loss: 4.3420732361929755\n",
      "Generated sentence:\n",
      "[',', 'rise', 'flow', 'mirror', 'helped', 'killed', 'killed', 'chase', 'chance', 'day']\n",
      "Length: 10\n",
      "Epoch: 116\n",
      "Ave Loss: 4.342053277151925\n",
      "Generated sentence:\n",
      "['rage', 'grow', 'remember', 'watch', 'love', 'came', 'seems', 'would', 'never', 'came']\n",
      "Length: 10\n",
      "Epoch: 117\n",
      "Ave Loss: 4.342033215931484\n",
      "Generated sentence:\n",
      "['knew', 'rage', 'successful', 'model', 'fulfill', 'perform', 'make', 'quite', 'beyond', 'growing']\n",
      "Length: 10\n",
      "Epoch: 118\n",
      "Ave Loss: 4.342012984412057\n",
      "Generated sentence:\n",
      "[',', 'rapper', 'end', 'mirror', 'front', 'lyric', 'chance', 'front', 'quite', 'one']\n",
      "Length: 10\n",
      "Epoch: 119\n",
      "Ave Loss: 4.3419927188328336\n",
      "Generated sentence:\n",
      "['named', 'growing', 'quite', 'chance', 'rapper', 'flow', 'beyond', 'work', 'successful', 'better']\n",
      "Length: 10\n",
      "Epoch: 120\n",
      "Ave Loss: 4.341972214835031\n",
      "Generated sentence:\n",
      "['perform', 'circumstance', 'knew', 'always', 'never', 'named', 'time', 'many', 'escape', 'mood']\n",
      "Length: 10\n",
      "Epoch: 121\n",
      "Ave Loss: 4.341951813016619\n",
      "Generated sentence:\n",
      "['circumstance', 'stop', 'knew', 'hard', 'day', 'killed', 'better', 'fulfill', 'music', 'practicing']\n",
      "Length: 10\n",
      "Epoch: 122\n",
      "Ave Loss: 4.341931240899222\n",
      "Generated sentence:\n",
      "[',', 'end', 'flow', 'chase', 'day', 'love', 'never', 'came', 'rapper', 'better']\n",
      "Length: 10\n",
      "Epoch: 123\n",
      "Ave Loss: 4.341910566602435\n",
      "Generated sentence:\n",
      "['work', 'chase', 'mood', 'achieved', 'growing', 'escape', 'one', 'neighborhood', 'always', 'stop']\n",
      "Length: 10\n",
      "Epoch: 124\n",
      "Ave Loss: 4.341889585767474\n",
      "Generated sentence:\n",
      "['mood', 'raised', 'music', 'growing', 'came', 'boy', 'lyric', 'finally', 'change', 'achieved']\n",
      "Length: 10\n",
      "Epoch: 125\n",
      "Ave Loss: 4.341868604932513\n",
      "Generated sentence:\n",
      "['mirror', 'circumstance', 'beyond', 'troubled', 'hood', 'successful', 'struggle', 'make', 'perform', 'better']\n",
      "Length: 10\n",
      "Epoch: 126\n",
      "Ave Loss: 4.3418474197387695\n",
      "Generated sentence:\n",
      "['writing', 'reality', 'music', 'boy', 'struggle', 'boy', 'front', 'successful', 'stage', 'top']\n",
      "Length: 10\n",
      "Epoch: 127\n",
      "Ave Loss: 4.341826166425433\n",
      "Generated sentence:\n",
      "['writing', 'time', 'boy', 'forgot', 'chase', 'showing', 'circumstance', 'helped', 'watch', 'end']\n",
      "Length: 10\n",
      "Epoch: 128\n",
      "Ave Loss: 4.341804947171893\n",
      "Generated sentence:\n",
      "['writing', 'chance', 'model', 'struggle', 'upon', 'never', 'model', 'boy', 'perform', 'perform']\n",
      "Length: 10\n",
      "Epoch: 129\n",
      "Ave Loss: 4.341783387320382\n",
      "Generated sentence:\n",
      "['remember', 'neighborhood', 'rhyme', 'helped', 'circumstance', 'circumstance', 'mood', 'life', 'writing', 'perform']\n",
      "Length: 10\n",
      "Epoch: 130\n",
      "Ave Loss: 4.341761793409075\n",
      "Generated sentence:\n",
      "['upon', 'perform', 'showing', 'showing', 'remember', 'role', 'rhyme', 'seems', 'better', 'one']\n",
      "Length: 10\n",
      "Epoch: 131\n",
      "Ave Loss: 4.341740029198783\n",
      "Generated sentence:\n",
      "['work', ',', 'rap', 'knew', 'finally', 'work', 'strife', 'faced', 'chance', 'mood']\n",
      "Length: 10\n",
      "Epoch: 132\n",
      "Ave Loss: 4.341718264988491\n",
      "Generated sentence:\n",
      "['came', 'role', 'came', 'struggle', 'came', 'mike', 'could', 'time', 'beat', 'hard']\n",
      "Length: 10\n",
      "Epoch: 133\n",
      "Ave Loss: 4.341696296419416\n",
      "Generated sentence:\n",
      "['rage', 'crowd', 'rhyme', 'change', 'fulfill', 'showing', 'beyond', 'killed', 'hard', 'fulfill']\n",
      "Length: 10\n",
      "Epoch: 134\n",
      "Ave Loss: 4.341674157551357\n",
      "Generated sentence:\n",
      "['model', 'always', 'change', 'front', 'helped', 'love', 'stage', 'growing', 'knew', 'rage']\n",
      "Length: 10\n",
      "Epoch: 135\n",
      "Ave Loss: 4.341652052743094\n",
      "Generated sentence:\n",
      "['dream', 'see', 'practicing', 'mike', 'grow', 'always', 'chance', 'boy', 'hard', 'time']\n",
      "Length: 10\n",
      "Epoch: 136\n",
      "Ave Loss: 4.341629675456455\n",
      "Generated sentence:\n",
      "['end', 'never', 'killed', 'life', 'one', 'end', 'finally', 'music', 'front', 'see']\n",
      "Length: 10\n",
      "Epoch: 137\n",
      "Ave Loss: 4.341607127870832\n",
      "Generated sentence:\n",
      "['make', 'writing', 'rage', ',', ',', 'grow', 'boy', 'better', 'rage', 'change']\n",
      "Length: 10\n",
      "Epoch: 138\n",
      "Ave Loss: 4.341584546225412\n",
      "Generated sentence:\n",
      "['dream', 'writing', 'top', 'neighborhood', 'upon', 'watch', 'named', 'beat', 'see', 'seems']\n",
      "Length: 10\n",
      "Epoch: 139\n",
      "Ave Loss: 4.341561896460397\n",
      "Generated sentence:\n",
      "['one', 'model', 'crowd', 'never', 'lyric', 'hood', 'hood', 'fulfill', 'music', 'hood']\n",
      "Length: 10\n",
      "Epoch: 140\n",
      "Ave Loss: 4.3415390423366\n",
      "Generated sentence:\n",
      "['make', 'front', 'finally', 'mood', 'front', 'killed', 'end', 'never', 'successful', 'raised']\n",
      "Length: 10\n",
      "Epoch: 141\n",
      "Ave Loss: 4.341516051973615\n",
      "Generated sentence:\n",
      "['chance', 'make', 'circumstance', 'achieved', 'came', 'always', 'kid', 'kid', 'rage', 'chance']\n",
      "Length: 10\n",
      "Epoch: 142\n",
      "Ave Loss: 4.34149306161063\n",
      "Generated sentence:\n",
      "['achieved', 'model', 'named', 'achieved', 'change', 'successful', 'practicing', 'end', 'rage', 'work']\n",
      "Length: 10\n",
      "Epoch: 143\n",
      "Ave Loss: 4.341469832829067\n",
      "Generated sentence:\n",
      "['chase', 'knew', 'time', 'life', 'killed', 'neighborhood', 'neighborhood', 'made', 'work', 'chance']\n",
      "Length: 10\n",
      "Epoch: 144\n",
      "Ave Loss: 4.341446501868112\n",
      "Generated sentence:\n",
      "['music', 'top', 'watch', ',', 'circumstance', 'mike', 'neighborhood', 'strife', 'upon', 'stop']\n",
      "Length: 10\n",
      "Epoch: 145\n",
      "Ave Loss: 4.341423034667969\n",
      "Generated sentence:\n",
      "['change', 'world', 'hood', 'lyric', 'fulfill', 'top', 'reality', 'love', 'fulfill', 'neighborhood']\n",
      "Length: 10\n",
      "Epoch: 146\n",
      "Ave Loss: 4.341399397168841\n",
      "Generated sentence:\n",
      "['day', 'crowd', 'mirror', 'role', 'could', 'successful', 'flow', 'escape', 'dream', 'work']\n",
      "Length: 10\n",
      "Epoch: 147\n",
      "Ave Loss: 4.341375691550119\n",
      "Generated sentence:\n",
      "['watch', 'started', 'front', 'boy', 'role', 'watch', 'growing', 'flow', 'named', 'quite']\n",
      "Length: 10\n",
      "Epoch: 148\n",
      "Ave Loss: 4.3413518496922086\n",
      "Generated sentence:\n",
      "['came', 'model', 'started', 'mike', 'perform', 'work', 'rhyme', 'mood', 'better', 'boy']\n",
      "Length: 10\n",
      "Epoch: 149\n",
      "Ave Loss: 4.3413278715951105\n",
      "Generated sentence:\n",
      "['lyric', 'change', 'forgot', 'dream', 'life', 'quite', 'escape', 'circumstance', ',', 'achieved']\n",
      "Length: 10\n",
      "Epoch: 150\n",
      "Ave Loss: 4.341303586959839\n",
      "Generated sentence:\n",
      "['time', 'see', 'mood', 'helped', 'watch', 'would', 'finally', 'fulfill', 'practicing', 'day']\n",
      "Length: 10\n",
      "Epoch: 151\n",
      "Ave Loss: 4.341279370444162\n",
      "Generated sentence:\n",
      "['seems', 'helped', 'made', 'world', 'named', 'seems', 'lyric', 'came', 'stage', 'achieved']\n",
      "Length: 10\n",
      "Epoch: 152\n",
      "Ave Loss: 4.341254949569702\n",
      "Generated sentence:\n",
      "['hard', 'change', 'watch', 'love', 'achieved', 'make', 'lyric', 'make', 'see', 'remember']\n",
      "Length: 10\n",
      "Epoch: 153\n",
      "Ave Loss: 4.341230358396258\n",
      "Generated sentence:\n",
      "['work', 'writing', 'front', 'upon', 'rapper', 'rage', 'finally', 'killed', 'mood', 'change']\n",
      "Length: 10\n",
      "Epoch: 154\n",
      "Ave Loss: 4.341205733163016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated sentence:\n",
      "['growing', 'one', 'chase', 'boy', 'role', ',', 'showing', 'showing', 'hood', 'reality']\n",
      "Length: 10\n",
      "Epoch: 155\n",
      "Ave Loss: 4.341181005750384\n",
      "Generated sentence:\n",
      "['beyond', 'quite', 'mirror', 'growing', 'beat', 'escape', 'successful', 'showing', 'flow', 'kid']\n",
      "Length: 10\n",
      "Epoch: 156\n",
      "Ave Loss: 4.341156005859375\n",
      "Generated sentence:\n",
      "['rage', 'work', 'beyond', 'rapper', 'made', 'change', 'life', 'achieved', 'successful', 'showing']\n",
      "Length: 10\n",
      "Epoch: 157\n",
      "Ave Loss: 4.341130903788975\n",
      "Generated sentence:\n",
      "['knew', 'music', 'hood', 'killed', 'never', 'better', 'mirror', 'started', 'rise', 'work']\n",
      "Length: 10\n",
      "Epoch: 158\n",
      "Ave Loss: 4.341105733598981\n",
      "Generated sentence:\n",
      "['would', 'quite', 'mirror', 'killed', 'time', 'better', 'struggle', 'could', 'upon', 'seems']\n",
      "Length: 10\n",
      "Epoch: 159\n",
      "Ave Loss: 4.3410802228110175\n",
      "Generated sentence:\n",
      "['front', 'mood', 'end', 'role', 'always', 'reality', 'model', 'beat', 'make', 'helped']\n",
      "Length: 10\n",
      "Epoch: 160\n",
      "Ave Loss: 4.341054814202445\n",
      "Generated sentence:\n",
      "['end', 'crowd', 'time', 'practicing', 'named', 'finally', 'chase', 'quite', 'reality', 'love']\n",
      "Length: 10\n",
      "Epoch: 161\n",
      "Ave Loss: 4.341029099055699\n",
      "Generated sentence:\n",
      "['lyric', 'change', 'seems', 'mirror', 'made', 'successful', 'showing', 'make', 'strife', 'rhyme']\n",
      "Length: 10\n",
      "Epoch: 162\n",
      "Ave Loss: 4.341003383908953\n",
      "Generated sentence:\n",
      "['forgot', 'came', 'crowd', 'came', 'mirror', 'rapper', 'hood', 'killed', 'growing', 'front']\n",
      "Length: 10\n",
      "Epoch: 163\n",
      "Ave Loss: 4.340977566582816\n",
      "Generated sentence:\n",
      "['day', 'forgot', 'chance', 'named', 'perform', 'raised', 'love', 'made', 'upon', 'role']\n",
      "Length: 10\n",
      "Epoch: 164\n",
      "Ave Loss: 4.340951578957694\n",
      "Generated sentence:\n",
      "['escape', 'see', 'rapper', 'kid', 'hard', 'raised', 'faced', 'hard', 'faced', 'crowd']\n",
      "Length: 10\n",
      "Epoch: 165\n",
      "Ave Loss: 4.340925557272775\n",
      "Generated sentence:\n",
      "['escape', 'dream', 'time', 'writing', ',', 'showing', 'beyond', 'world', 'killed', 'rise']\n",
      "Length: 10\n",
      "Epoch: 166\n",
      "Ave Loss: 4.340899297169277\n",
      "Generated sentence:\n",
      "['many', 'mirror', 'role', 'upon', 'role', 'growing', 'end', 'made', 'could', 'would']\n",
      "Length: 10\n",
      "Epoch: 167\n",
      "Ave Loss: 4.340872934886387\n",
      "Generated sentence:\n",
      "['chase', 'love', 'work', 'rhyme', 'could', 'beyond', 'mirror', 'showing', 'model', 'finally']\n",
      "Length: 10\n",
      "Epoch: 168\n",
      "Ave Loss: 4.340846402304513\n",
      "Generated sentence:\n",
      "['model', 'rage', 'helped', 'strife', 'perform', 'music', 'seems', 'mirror', 'kid', 'neighborhood']\n",
      "Length: 10\n",
      "Epoch: 169\n",
      "Ave Loss: 4.340819801603045\n",
      "Generated sentence:\n",
      "['lyric', 'reality', 'dream', 'hard', 'would', 'would', 'role', 'rapper', 'crowd', 'model']\n",
      "Length: 10\n",
      "Epoch: 170\n",
      "Ave Loss: 4.340793064662388\n",
      "Generated sentence:\n",
      "['make', 'dream', 'struggle', 'rise', 'would', 'raised', 'chance', 'mood', 'make', 'forgot']\n",
      "Length: 10\n",
      "Epoch: 171\n",
      "Ave Loss: 4.340766157422747\n",
      "Generated sentence:\n",
      "['escape', 'struggle', 'hard', 'struggle', 'one', 'hood', 'kid', 'circumstance', 'rise', 'neighborhood']\n",
      "Length: 10\n",
      "Epoch: 172\n",
      "Ave Loss: 4.340739079884121\n",
      "Generated sentence:\n",
      "['make', 'remember', 'struggle', 'work', 'came', 'one', 'role', 'neighborhood', 'fulfill', 'mike']\n",
      "Length: 10\n",
      "Epoch: 173\n",
      "Ave Loss: 4.3407118661063055\n",
      "Generated sentence:\n",
      "['named', 'hood', 'hard', 'beyond', 'stop', 'kid', 'knew', 'achieved', 'rapper', 'seems']\n",
      "Length: 10\n",
      "Epoch: 174\n",
      "Ave Loss: 4.3406845501491\n",
      "Generated sentence:\n",
      "['knew', 'make', 'mirror', 'knew', 'helped', 'neighborhood', 'better', 'mood', 'watch', 'chance']\n",
      "Length: 10\n",
      "Epoch: 175\n",
      "Ave Loss: 4.340657132012503\n",
      "Generated sentence:\n",
      "[',', 'forgot', 'stop', 'finally', 'mood', 'kid', ',', 'lyric', 'achieved', 'one']\n",
      "Length: 10\n",
      "Epoch: 176\n",
      "Ave Loss: 4.340629543576922\n",
      "Generated sentence:\n",
      "['writing', 'forgot', 'hard', 'many', 'rage', 'life', 'chase', 'many', 'top', 'fulfill']\n",
      "Length: 10\n",
      "Epoch: 177\n",
      "Ave Loss: 4.340601784842355\n",
      "Generated sentence:\n",
      "['model', 'mood', 'escape', 'never', 'mike', 'rap', 'top', 'model', 'made', 'escape']\n",
      "Length: 10\n",
      "Epoch: 178\n",
      "Ave Loss: 4.340573923928397\n",
      "Generated sentence:\n",
      "['flow', 'growing', 'end', 'struggle', 'life', 'growing', 'role', 'world', 'front', 'rage']\n",
      "Length: 10\n",
      "Epoch: 179\n",
      "Ave Loss: 4.340545858655657\n",
      "Generated sentence:\n",
      "['troubled', 'would', 'end', 'many', 'finally', 'could', 'achieved', 'make', 'always', 'successful']\n",
      "Length: 10\n",
      "Epoch: 180\n",
      "Ave Loss: 4.340517793382917\n",
      "Generated sentence:\n",
      "['day', 'neighborhood', 'writing', 'always', 'hood', 'achieved', 'hard', 'top', 'world', 'music']\n",
      "Length: 10\n",
      "Epoch: 181\n",
      "Ave Loss: 4.340489557811192\n",
      "Generated sentence:\n",
      "['day', 'never', 'practicing', 'faced', 'chance', 'hard', 'day', 'beyond', 'stage', 'lyric']\n",
      "Length: 10\n",
      "Epoch: 182\n",
      "Ave Loss: 4.340461151940482\n",
      "Generated sentence:\n",
      "['end', 'top', 'chance', 'role', 'would', 'writing', 'mirror', 'love', 'rhyme', 'reality']\n",
      "Length: 10\n",
      "Epoch: 183\n",
      "Ave Loss: 4.340432609830584\n",
      "Generated sentence:\n",
      "['writing', 'front', 'always', 'practicing', 'beat', 'grow', 'beat', 'flow', 'watch', 'reality']\n",
      "Length: 10\n",
      "Epoch: 184\n",
      "Ave Loss: 4.3404039314814975\n",
      "Generated sentence:\n",
      "['could', 'rise', 'time', 'make', 'mike', 'one', 'life', 'growing', 'troubled', 'hood']\n",
      "Length: 10\n",
      "Epoch: 185\n",
      "Ave Loss: 4.340375116893223\n",
      "Generated sentence:\n",
      "['see', 'reality', 'strife', 'rhyme', 'mirror', 'knew', 'time', 'time', 'remember', 'beat']\n",
      "Length: 10\n",
      "Epoch: 186\n",
      "Ave Loss: 4.340346166065761\n",
      "Generated sentence:\n",
      "['mirror', 'rhyme', 'successful', 'perform', 'world', 'achieved', 'could', 'change', 'killed', 'rapper']\n",
      "Length: 10\n",
      "Epoch: 187\n",
      "Ave Loss: 4.340317044939313\n",
      "Generated sentence:\n",
      "['writing', 'killed', 'mood', 'chance', 'started', 'finally', 'many', 'upon', 'chase', 'achieved']\n",
      "Length: 10\n",
      "Epoch: 188\n",
      "Ave Loss: 4.340287855693272\n",
      "Generated sentence:\n",
      "['started', 'finally', 'neighborhood', 'could', 'mike', 'helped', 'mirror', 'change', 'many', 'mirror']\n",
      "Length: 10\n",
      "Epoch: 189\n",
      "Ave Loss: 4.340258530208042\n",
      "Generated sentence:\n",
      "['flow', 'watch', 'escape', 'mood', 'knew', 'started', 'love', 'mirror', 'mike', 'escape']\n",
      "Length: 10\n",
      "Epoch: 190\n",
      "Ave Loss: 4.340229068483625\n",
      "Generated sentence:\n",
      "['boy', 'role', 'reality', 'beyond', 'model', 'writing', 'always', 'time', 'never', 'seems']\n",
      "Length: 10\n",
      "Epoch: 191\n",
      "Ave Loss: 4.340199436460223\n",
      "Generated sentence:\n",
      "['mood', 'upon', 'would', 'made', 'make', 'escape', 'hood', 'make', 'crowd', 'boy']\n",
      "Length: 10\n",
      "Epoch: 192\n",
      "Ave Loss: 4.340169566018241\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [40]\u001b[0m, in \u001b[0;36m<cell line: 37>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     41\u001b[0m average_losses\u001b[38;5;241m.\u001b[39mappend(ave_loss)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAve Loss: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(ave_loss))\n\u001b[1;32m---> 45\u001b[0m generated_sentence \u001b[38;5;241m=\u001b[39m \u001b[43mcallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerated sentence:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(generated_sentence)\n",
      "Input \u001b[1;32mIn [37]\u001b[0m, in \u001b[0;36mcallback\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     29\u001b[0m x_predictions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(x_predictions)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     30\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x_predictions, start_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 32\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     34\u001b[0m next_index \u001b[38;5;241m=\u001b[39m sample(preds)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m#print(\"next_index: {}\".format(next_index))\u001b[39;00m\n",
      "Input \u001b[1;32mIn [38]\u001b[0m, in \u001b[0;36mMultiLayerPerceptron.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# f(x) = a(f(x))\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     14\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(x))\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def train_fn(model, optimizer, loss_fn, device):\n",
    "    ave_loss = 0\n",
    "    count = 0\n",
    "    \n",
    "    for i, data in enumerate(x):\n",
    "        data = x[i]\n",
    "        targets = y[i]\n",
    "        \n",
    "        # Forward\n",
    "        predictions = model.forward(data)\n",
    "        \n",
    "        predictions = F.softmax(predictions, dim=-1)\n",
    "        \n",
    "        loss = loss_fn(predictions, targets)\n",
    "        \n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        count += 1\n",
    "        ave_loss += loss.item()\n",
    "    \n",
    "    ave_loss = ave_loss / count\n",
    "\n",
    "    return ave_loss\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "average_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"Epoch: {}\".format(epoch))\n",
    "    ave_loss = train_fn(model, optimizer, criterion, device)\n",
    "    \n",
    "    average_losses.append(ave_loss)\n",
    "        \n",
    "    print(\"Ave Loss: {}\".format(ave_loss))\n",
    "    \n",
    "    generated_sentence = callback(model)\n",
    "    \n",
    "    print(\"Generated sentence:\")\n",
    "    print(generated_sentence)\n",
    "    print(\"Length: {}\".format(len(generated_sentence)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "0e5a6075eb3e20c6cbfd0f7ac0fb5393b74a257f3d9b10c3d81197c99cd05ef7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
